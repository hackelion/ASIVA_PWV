{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oaj2Di_jT7w2"
      },
      "outputs": [],
      "source": [
        "# Este código foi desenvolvido usando o Google Collaboratory\n",
        "# e roda utilizando arquivos em um Google Drive\n",
        "\n",
        "########################################################\n",
        "##### ANTES DE RODAR DEFINA AS SEGUINTES VARIÁVEIS #####\n",
        "########################################################\n",
        "\n",
        "# Endereço (no drive) do arquivo csv da lookup table gerado no LibRadtran:\n",
        "# O arquivo deve conter PWV, Cosseno do ângulo zenital, Airmass e Radiância (separados por vírgulas).\n",
        "data_table = '/content/drive/My Drive/Doutorado/Dados/Tabelas/lt_2.0_10082018_CH4.csv'\n",
        "\n",
        "# Valores inicial, final e incremento de PWV usado na lookup table:\n",
        "Vini = 4.0\n",
        "Vfin = 25.0\n",
        "Vinc = 0.1\n",
        "\n",
        "# Valores inicial, final e incremento do cosseno do angulo zenital usados nas simulações:\n",
        "Cini = -1.00\n",
        "Cfin = -0.50\n",
        "Cinc = 0.025\n",
        "\n",
        "# Dados do ASIVA - Endereço da pasta onde estão os arquivos de diferenças de contagens no drive (filtrando dados do canal 4):\n",
        "path4 = '/content/drive/My Drive/Doutorado/Dados/10-08-2018_Noturno/*diff_4.fits'\n",
        "\n",
        "# Código de identificação do arquivo de massas de ar no drive:\n",
        "am_id = '1imaUyPaSLW08b0uQlHFBRE-GKztXVjcF'\n",
        "\n",
        "# Código de identificação do arquivo de ganhos no drive:\n",
        "gn_id = '1anDF0bAK4Mk3JJmwCwvUhoVyfvFG_X_-'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWWNh0vSU1bc",
        "outputId": "da383bd3-7544-4207-c012-daf85bedc72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.8/dist-packages (0.9.20)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.8/dist-packages (from kora) (1.5.28)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from kora) (7.9.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastcore->kora) (22.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastcore->kora) (23.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->kora) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->kora) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Imports gerais:\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import glob\n",
        "\n",
        "from scipy.integrate import simps\n",
        "from scipy.interpolate import interp1d\n",
        "import scipy.integrate as integrate\n",
        "\n",
        "from scipy.optimize import curve_fit\n",
        "from matplotlib.mathtext import DejaVuSerifFontConstants\n",
        "import time\n",
        "\n",
        "# Função que retorna o file ID a partir do endereço no drive\n",
        "!pip install kora\n",
        "from kora.xattr import get_id\n",
        "\n",
        "# Montando o drive para acessar os arquivos csv:\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Autencicação para acessar arquivos FITS:\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from astropy.io import fits\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IBXalaEa5EO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ae6323-5bc0-44dd-d6b6-d27cab99fb8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-66dc4ff67ff2>:19: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return (t1 * 1.19e+08 * lam1**-5) / (np.exp(1.44e+04 / (lam1 * T)) - 1)\n",
            "<ipython-input-21-66dc4ff67ff2>:19: RuntimeWarning: overflow encountered in exp\n",
            "  return (t1 * 1.19e+08 * lam1**-5) / (np.exp(1.44e+04 / (lam1 * T)) - 1)\n",
            "<ipython-input-21-66dc4ff67ff2>:22: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return (t4 * 1.19e+08 * lam4**-5) / (np.exp(1.44e+04 / (lam4 * T)) - 1)\n",
            "<ipython-input-21-66dc4ff67ff2>:22: RuntimeWarning: overflow encountered in exp\n",
            "  return (t4 * 1.19e+08 * lam4**-5) / (np.exp(1.44e+04 / (lam4 * T)) - 1)\n"
          ]
        }
      ],
      "source": [
        "# Método para integração da função de Planck\n",
        "\n",
        "# Transmitância para CH1 e CH4\n",
        "lam1 = np.array([7.5,\t7.6,\t7.7,\t7.8,\t7.9,\t8,\t8.1,\t8.2,\t8.3,\t8.4,\t8.5,\t8.6,\t8.7,\t8.8,\t8.9,\t9,\t9.1,\t9.2,\t9.3,\t9.4,\t9.5,\t9.6,\t9.7,\t9.8,\t9.9,\t10])\n",
        "t1 = np.array([0,\t0.00099387241,\t0.0037543261,\t0.016397096,\t0.067411996,\t0.16470027,\t0.23448369,\t0.28485084,\t0.32886598,\t0.36326829,\t0.37955591,\t0.37672785,\t0.37035781,\t0.38823766,\t0.44920856,\t0.49278599,\t0.43715978,\t0.35334194,\t0.26878348,\t0.13254657,\t0.047449771,\t0.014290923,\t0.0063342853,\t0.0017594688,\t0,\t0])\n",
        "\n",
        "lam4 = np.array([9.5, 9.6, 9.7, 9.8, 9.9, 10, 10.1, 10.2, 10.3, 10.4, 10.5, 10.6, 10.7, 10.8, 10.9, 11, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 11.7, 11.8, 11.9, 12, 12.1, 12.2, 12.3, 12.4, 12.5, 12.6, 12.7, 12.8, 12.9, 13])\n",
        "t4 = np.array([0.0000000, 6.1639049e-03, 1.2173898e-02, 2.7315959e-02, 6.6134155e-02, 1.5677769e-01, 3.1759289e-01, 5.0121820e-01, 6.2649029e-01, 6.6445202e-01, 6.7786473e-01, 7.0090240e-01, 7.2765547e-01, 7.4226588e-01, 7.3759609e-01, 7.0764691e-01, 6.6859865e-01, 6.3946754e-01, 6.2751961e-01, 6.2927783e-01, 6.3590199e-01, 6.3487315e-01, 6.2753671e-01, 6.1468023e-01, 5.9755743e-01, 5.8034897e-01, 5.6401944e-01, 5.4896957e-01, 5.3071028e-01, 4.8840195e-01, 3.5360095e-01, 1.7142840e-01, 7.3776573e-02, 3.4712266e-02, 1.7007021e-02, 0.0000000])\n",
        "\n",
        "# Integral da transmitância.\n",
        "It1 = simps(t1, lam1)\n",
        "It4 = simps(t4, lam4)\n",
        "\n",
        "# Temperatura de 0 a 500 K - Passo de 0.1 K.\n",
        "T = np.linspace(0, 500, num=5001)\n",
        "\n",
        "# BB = Integral(f(T)) / It\n",
        "def f1(T):\n",
        "    return (t1 * 1.19e+08 * lam1**-5) / (np.exp(1.44e+04 / (lam1 * T)) - 1)\n",
        "\n",
        "def f4(T):\n",
        "    return (t4 * 1.19e+08 * lam4**-5) / (np.exp(1.44e+04 / (lam4 * T)) - 1)\n",
        "\n",
        "BB1 = [simps(f1(x), lam1)/It1 for x in T]\n",
        "BB4 = [simps(f4(x), lam4)/It4 for x in T]\n",
        "\n",
        "# Função para fazer a interpolação\n",
        "BB1_interp = interp1d(T, BB1)\n",
        "BB4_interp = interp1d(T, BB4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo um array com os códigos de identificação de todos os arquivos em uma pasta:\n",
        "\n",
        "# Obtem todos os endereços dos diff em ordem alfabética:\n",
        "file_path4 = glob.glob(path4)\n",
        "file_path4 = sorted(file_path4)\n",
        "\n",
        "data_diff4 = []\n",
        "\n",
        "for p4 in file_path4:\n",
        "  data_diff4.append(get_id(p4))\n",
        "\n",
        "print(data_diff4)"
      ],
      "metadata": {
        "id": "-_7POZkrb_dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f50883-9b4f-4b0f-ac94-0a11feca64c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1Of_V4TlLFCXWDMKDY2u7LJ68Ra5DpIVQ', '1QlF_E9pMW8xiCGDpME4-QKTA3b7pxNk1', '1Pic3dCzQ2AIaCz0vWnxlFqAUWlpNRmFp', '1tBExAqJho0zeUPl7HZSqhHDMpMLcbpks', '1XJPGcZBa8P03FyfO_5qLBwnsCmZ1PKRN', '1h9WyvdYO9wNcRDhOWMyrI4EawhUyEfU_', '1u95YNSjdLSyMcpRrMUj6gkXFHW7MdEDs', '1vq2_5MegnW9bbXrwmdIT7WVJ2V-I3nUn', '10GuU2ONW_F5x4PEHZJ4oJ9kxAnE2ISPy', '19XzVgQmFDj3qALWU0APH0o3W7xTZUNAa', '1IU5XgUTE1XStpr7IYDsY_oFiaIdr5cE4', '1ijtZzU_GwyBhrjRf60XiHOBTsi4DjN8Z', '13K_yNHxgQqOfjc1Hh_UuG80wq-u-dZGA', '1GSXU6PsLC6ALr2eUdM7F2ofteUChnd3F', '1w2DK6C0S4kqc-ok5drFO0LoIZMMADUku', '1AzgPYHlRL_aIlq0cnyaorDTN_Y1JZ1kX', '1AI4Q5hOBQGP85jRzyxkVop8fV6fbCE1p', '1n-uJpyL-iJiXKAfzHtj3yYRXDRGe7Y72', '1jcGh9SSPjZILmc1YzlOwiue_3dXoIH1H', '1qEViO1joFRv1UlYChPzvRE511CqG63ck', '1YAnIU7NOguu1AvpFKR7Dq2KsLnEEZXr5', '1i5qXFRp1i0RY52E-1JA0wAX9ch7enVmM', '1HmkVVfV29xWLaQDUpUVkt5ySGQ983RDA', '15D7F0uOrcEUHcJgoUlL7Ctlp9UJZ_9YJ', '1c6TwJK1ehHF9ooRSEd6eQF3RxPrtDk4M']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS5irTuWZqUT"
      },
      "outputs": [],
      "source": [
        "# Importando arquivo de airmass e ganhos do Google Drive a partir de seus códigos:\n",
        "\n",
        "# Arquivo de airmass:\n",
        "am = 'airmass.fit'\n",
        "dl = drive.CreateFile({'id': am_id})\n",
        "dl.GetContentFile(am)\n",
        "\n",
        "airmass = fits.getdata(am)\n",
        "\n",
        "\n",
        "# Arquivo de ganho novo (70C) - CH4.\n",
        "gn4 = 'gn_ch4.fit'\n",
        "dl = drive.CreateFile({'id': gn_id})\n",
        "dl.GetContentFile(gn4)\n",
        "\n",
        "gain4 = fits.getdata(gn4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr-GxGYlU5dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a52971d-ea8d-4ed7-db93-97364bc7d778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sim_am = [1.         1.02564103 1.05263158 1.08108108 1.11111111 1.14285714\n",
            " 1.17647059 1.21212121 1.25       1.29032258 1.33333333 1.37931034\n",
            " 1.42857143 1.48148148 1.53846154 1.6        1.66666667 1.73913043\n",
            " 1.81818182 1.9047619  2.        ]\n"
          ]
        }
      ],
      "source": [
        "# Calcula o array de massas de ar usado nas simulações do libRadtran:\n",
        "\n",
        "n = ((Cfin - Cini)/Cinc)+1\n",
        "sim_cos = np.linspace(Cini, Cfin, round(n))\n",
        "sim_am = -1/sim_cos\n",
        "\n",
        "#print('sim_am = '+ str(sim_am) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvbpihroU9HI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f362288-f5f0-45b3-82ee-16d8f5e59eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWV = [ 4.   4.1  4.2  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.   5.1  5.2  5.3\n",
            "  5.4  5.5  5.6  5.7  5.8  5.9  6.   6.1  6.2  6.3  6.4  6.5  6.6  6.7\n",
            "  6.8  6.9  7.   7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.   8.1\n",
            "  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9  9.   9.1  9.2  9.3  9.4  9.5\n",
            "  9.6  9.7  9.8  9.9 10.  10.1 10.2 10.3 10.4 10.5 10.6 10.7 10.8 10.9\n",
            " 11.  11.1 11.2 11.3 11.4 11.5 11.6 11.7 11.8 11.9 12.  12.1 12.2 12.3\n",
            " 12.4 12.5 12.6 12.7 12.8 12.9 13.  13.1 13.2 13.3 13.4 13.5 13.6 13.7\n",
            " 13.8 13.9 14.  14.1 14.2 14.3 14.4 14.5 14.6 14.7 14.8 14.9 15.  15.1\n",
            " 15.2 15.3 15.4 15.5 15.6 15.7 15.8 15.9 16.  16.1 16.2 16.3 16.4 16.5\n",
            " 16.6 16.7 16.8 16.9 17.  17.1 17.2 17.3 17.4 17.5 17.6 17.7 17.8 17.9\n",
            " 18.  18.1 18.2 18.3 18.4 18.5 18.6 18.7 18.8 18.9 19.  19.1 19.2 19.3\n",
            " 19.4 19.5 19.6 19.7 19.8 19.9 20.  20.1 20.2 20.3 20.4 20.5 20.6 20.7\n",
            " 20.8 20.9 21.  21.1 21.2 21.3 21.4 21.5 21.6 21.7 21.8 21.9 22.  22.1\n",
            " 22.2 22.3 22.4 22.5 22.6 22.7 22.8 22.9 23.  23.1 23.2 23.3 23.4 23.5\n",
            " 23.6 23.7 23.8 23.9 24.  24.1 24.2 24.3 24.4 24.5 24.6 24.7 24.8 24.9\n",
            " 25. ]\n"
          ]
        }
      ],
      "source": [
        "# Gerando o array de PWVs usados na lookup table:\n",
        "\n",
        "num = ((Vfin - Vini)/Vinc)+1\n",
        "\n",
        "PWV = np.linspace(Vini, Vfin, round(num))\n",
        "\n",
        "#print('PWV = '+ str(PWV))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT5iSnKmVFd8"
      },
      "outputs": [],
      "source": [
        "# Carregando arquivo de lookup table gerada no libRadtran\n",
        "\n",
        "# Nomes das colunas do arquivo csv\n",
        "cols=['pwv','cos','airm','rad4']\n",
        "\n",
        "# Abrindo o arquivo csv com o pandas\n",
        "ltable = pd.read_csv(data_table, skiprows=1, sep=\",\", names=cols, na_values=[\"-9999\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uf62SuF6VeC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9380aa92-6043-4df6-9c63-15fe9662b093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/25\n",
            "2/25\n",
            "3/25\n",
            "4/25\n",
            "5/25\n",
            "6/25\n",
            "7/25\n"
          ]
        }
      ],
      "source": [
        "########################################\n",
        "##########  MÉTODO PRINCIPAL  ##########\n",
        "########################################\n",
        "\n",
        "# Obtém a coluna de vapor de água precipitável a partir da comparação de pontos \n",
        "# do envelope obtido de cada imagem do ASIVA com simulações da lookup table\n",
        "# gerada usando o libRadtran.\n",
        "# Canal 4 do ASIVA - 10 a 12 µm\n",
        "\n",
        "## Arrays para guardar os resultados de coluna de Vapor, Tempo e indice de comparação Qui:\n",
        "Vapor = []\n",
        "Tempo = []\n",
        "Qui = []\n",
        "\n",
        "# Laço que percorre toda a lista de arquivos (data_diff4):\n",
        "for i in range(len(data_diff4)):\n",
        "\n",
        "  # Contador para acompanhar o andamento:\n",
        "  print(str(i+1)+'/'+str(len(data_diff4)))\n",
        "  \n",
        "  # Carregando arquivo de diferença de contagens:\n",
        "  d4 = 'diff_ch4.fit'\n",
        "  dl = drive.CreateFile({'id': data_diff4[i]})\n",
        "  dl.GetContentFile(d4)\n",
        "  dif4 = fits.getdata(d4)\n",
        "\n",
        "  # Carregando dados e informações do header do arquivo:\n",
        "  hdul = fits.open(d4)\n",
        "  hdr = hdul[0].header\n",
        "  \n",
        "  # Obtendo o Tempo em horas:\n",
        "  eps = hdr['EPOCHS']\n",
        "  t = time.gmtime(eps)\n",
        "\n",
        "  # Obtendo temperaturas dos corpos negros interno e externo:\n",
        "  Ti = hdr['INTBBTMP']\n",
        "  Te = hdr['EXTBBTMP']\n",
        "\n",
        "  # Diferença de contagens e ganhos na região do corpo negro externo:\n",
        "  d4reg = dif4[499:504,259:274]\n",
        "  g4reg = gain4[499:504,259:274]\n",
        "\n",
        "  # Medianas calculadas na região do corpo negro externo:\n",
        "  df4 = np.median(d4reg)\n",
        "  g4ext = np.median(g4reg)\n",
        "  \n",
        "  # Calculo da radiância do corpo negro de referência (interno) na região do corpo negro externo:\n",
        "  Ti_K = Ti + 273.15\n",
        "  Ri4 = BB4_interp(Ti_K)\n",
        "\n",
        "  # Valor de contagens teórico para o corpo negro de referência na região da imagem do corpo negro externo:\n",
        "  c4int = Ri4*g4ext\n",
        "\n",
        "  # Calculo da radiância do corpo negro externo:\n",
        "  Te_K = Te + 273.15\n",
        "  Re4 = BB4_interp(Te_K)\n",
        "\n",
        "  # Valor de contagens teórico para o corpo negro externo:\n",
        "  c4ext = Re4*g4ext\n",
        "\n",
        "  # Offset:\n",
        "  off4 = c4ext - (df4 + c4int)\n",
        "\n",
        "  #######################\n",
        "  ### RADIÂNCIA - CH4 ###\n",
        "  #######################\n",
        "  radiance4 = ((dif4 + off4)/gain4) + Ri4\n",
        "\n",
        "  #############################################\n",
        "  ### Retirada de nuvens e limpeza de dados ###\n",
        "  #############################################\n",
        "  rad_limpa4 = np.copy(radiance4)\n",
        "\n",
        "  # Retirando dados da região externa à imagem:\n",
        "  fora = np.where(airmass < 1)\n",
        "  rad_limpa4[fora] = np.nan\n",
        "\n",
        "  # Mediana da radiância em torno de 3 massas de ar:\n",
        "  mediana_am3 = np.nanmedian(radiance4[np.logical_and(airmass < 3.01, airmass > 2.99)])\n",
        "\n",
        "  # Função que calcula o desvio padrão dos pixels adjacentes ao de coordenada [i,j]:\n",
        "  def desvio_pad (i, j, rad):\n",
        "    corte = [rad[i-1, j-1], rad[i, j-1], rad[i+1, j-1], rad[i-1, j], rad[i, j], rad[i+1, j], rad[i-1, j+1], rad[i, j+1], rad[i+1, j+1]]\n",
        "    return np.std(corte)\n",
        "\n",
        "  # Indetifica pixels a remover e transforma em NaN\n",
        "  for i in range (10, 510):\n",
        "    for j in range (30, 600):\n",
        "      if ((desvio_pad(i, j, radiance4) > 0.07)|(radiance4[i,j] > mediana_am3)):\n",
        "        rad_limpa4[i, j] = np.nan\n",
        "\n",
        "  #############################\n",
        "  ### RADIÂNCIA LIMPA - CH4 ###\n",
        "  #############################\n",
        "  radiance4 = np.copy(rad_limpa4)\n",
        "\n",
        "  # Obtenção dos valores do envelope para cada valor de airmass simulado (sim_am):\n",
        "  env_L4 = []\n",
        "\n",
        "  for x in sim_am:\n",
        "    fatia = np.where((airmass > x-0.001) & (airmass <= x+0.001))\n",
        "    med = np.nanmedian(radiance4[fatia])\n",
        "    min = np.nanmin(radiance4[fatia])\n",
        "    env_L4.append(med)\n",
        "\n",
        "  env_L4 = np.array(env_L4)\n",
        "\n",
        "  # Array para armazenar os valores de somatórias de diferenças quadráticas:\n",
        "  Q4 = []\n",
        "\n",
        "  for mm in PWV:\n",
        "    sel4 = ((ltable.pwv > mm-0.001)&(ltable.pwv < mm+0.001))\n",
        "    rad4_comp = np.array(ltable.rad4[sel4])\n",
        "    q = (rad4_comp - env_L4)/(rad4_comp + env_L4)\n",
        "    q2 = q*q\n",
        "    Q4.append(np.sum(q2))\n",
        "\n",
        "  Q4 = np.array(Q4)\n",
        "\n",
        "  # Obtendo valores de PWV que minimizam as diferenças quadráticas:\n",
        "  min_qui4 = np.min(Q4)\n",
        "  min_index4 = np.argmin(Q4)\n",
        "\n",
        "  # Salvando os valores obtidos nos arrays de Vapor e Tempo:\n",
        "  Vapor.append(PWV[min_index4])\n",
        "  Tempo.append(t[3] + (t[4]/60))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados:\n",
        "\n",
        "print('PWV (mm):')\n",
        "print(Vapor)\n",
        "print('Horário UTC:')\n",
        "print(Tempo)\n"
      ],
      "metadata": {
        "id": "UPAcaRIKidzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}